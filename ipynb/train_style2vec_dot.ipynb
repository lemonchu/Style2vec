{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import FontSampler\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 配置字体相关路径\n",
    "fonts_dir = \"./font_ds_mini/fonts\"            # 字体文件夹路径\n",
    "text_file = \"./font_ds/cleaned_text.txt\" # 文本文件路径\n",
    "chars_file = \"./font_ds/chars.txt\"                  # 常用字文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading fonts and rendering characters:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading fonts and rendering characters: 100%|██████████| 28/28 [01:00<00:00,  2.15s/it]\n",
      "Loading fonts and rendering characters: 100%|██████████| 28/28 [01:02<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# 初始化 FontSampler，同时会将字体分为 train/test 两类\n",
    "sampler = FontSampler(fonts_dir, text_file, chars_file, font_size=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------------------------\n",
    "# 定义模型\n",
    "model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT).to(device)\n",
    "embedding_dim = 128  # 输出嵌入向量的维度\n",
    "hidden_dim = 256     # 隐藏层维度\n",
    "\n",
    "# 修改最后全连接层，直接输出嵌入向量\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, hidden_dim),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(hidden_dim, hidden_dim),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(hidden_dim, embedding_dim)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_and_acc(style_vecs, group_size, alpha = 4.0):\n",
    "    \"\"\"\n",
    "    计算交叉熵损失和准确率。\n",
    "    对于每一行，重新生成一个 tensor，直接去除对角线（即自身的分数）。\n",
    "\n",
    "    :param style_vecs: 向量序列，由模型生成，形状为 [N, embedding_dim]\n",
    "    :param group_size: 每组的大小\n",
    "    :return: loss 和 acc\n",
    "    \"\"\"\n",
    "\n",
    "    # 对 style_vecs 进行 L2 标准化\n",
    "    style_vecs = F.normalize(style_vecs, p=2, dim=1)\n",
    "    \n",
    "    # 计算点积，然后对 0 取 max，再提升到 alpha 次方\n",
    "    dot_prod = torch.matmul(style_vecs, style_vecs.T)\n",
    "    similarity_matrix = torch.clamp(dot_prod, min=1e-8) ** alpha\n",
    "\n",
    "    N = similarity_matrix.size(0)\n",
    "    losses = []\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        row = similarity_matrix[i]  # shape: [N]\n",
    "        # 重新构造一个 tensor，去除自身的分数（第 i 个元素）\n",
    "        new_row = torch.cat((row[:i], row[i+1:]))  # shape: [N-1]\n",
    "        # 对 new_row 进行归一化\n",
    "        new_row = F.normalize(new_row, p=1, dim=0)\n",
    "        \n",
    "        # 构造目标分布：对于当前行所属的组（group_start 到 group_end-1），除去自身，每个目标均为 1/(group_size-1)\n",
    "        target = torch.zeros_like(new_row)\n",
    "        group_start = (i // group_size) * group_size\n",
    "        group_end = group_start + group_size -1\n",
    "        target[group_start:group_end] = 1.0 / (group_size - 1)\n",
    "        \n",
    "        # 计算 KL 散度损失\n",
    "        row_loss = F.kl_div(new_row.log(), target, reduction='sum')\n",
    "        losses.append(row_loss)\n",
    "\n",
    "        # 计算准确率：\n",
    "        # 从 new_row 选取 top-(group_size-1)，如果这些位置对应的原始索引均落在同一组中，则算作正确\n",
    "        topk_indices = new_row.topk(group_size - 1).indices\n",
    "        correct_in_row = ((topk_indices >= group_start) & (topk_indices < group_end)).sum().item()\n",
    "        correct += correct_in_row\n",
    "\n",
    "    loss = torch.stack(losses).mean()\n",
    "    acc = correct / ((group_size - 1) * N)\n",
    "\n",
    "    # 以 1e-3 的概率展示相似度矩阵 softmax\n",
    "    # if random.random() < 1e-3:\n",
    "    #     print(f\"Sim Matrix: {similarity_matrix}\")\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 训练和验证步骤（loss 基于 word2vec 风格的 compute_loss）\n",
    "def train_step(model, epoch, data_loader, optimizer, batch_size, font_size, group_size):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    progress_bar = tqdm(data_loader, desc=f'Epoch {epoch + 1} - Training', leave=True)\n",
    "    for batch in progress_bar:\n",
    "        # Flatten the batch into a single tensor\n",
    "        flattened_batch = [img.to(device) for sample in batch for img in sample]  # Flatten the nested list\n",
    "        batch_tensor = torch.stack(flattened_batch).squeeze(1)  # Shape: [total_images_in_batch, C, H, W]\n",
    "\n",
    "        # Pass the entire batch through the model\n",
    "        style_vecs = model(batch_tensor)  # Shape: [total_images_in_batch, embedding_dim]\n",
    "\n",
    "        # Reshape the output to match the expected input shape for compute_loss_and_acc\n",
    "        style_vecs = style_vecs.view(batch_size, font_size * group_size, -1)  # Shape: [batch_size, group_size, embedding_dim]\n",
    "        \n",
    "        # Compute the loss and accuracy\n",
    "        loss, acc = 0, 0\n",
    "        for i in range(batch_size):\n",
    "            sample_loss, sample_acc = compute_loss_and_acc(style_vecs[i], group_size)\n",
    "            loss += sample_loss\n",
    "            acc += sample_acc\n",
    "\n",
    "        loss /= batch_size\n",
    "        acc /= batch_size\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "        progress_bar.set_postfix(loss=loss.item(), acc=acc)\n",
    "    progress_bar.close()\n",
    "\n",
    "    return total_loss / len(data_loader), total_acc / len(data_loader)\n",
    "\n",
    "def validate(model, data_loader, batch_size, font_size, group_size):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc=\"Validating\", leave=True)\n",
    "        for batch in progress_bar:\n",
    "            # Flatten the batch into a single tensor\n",
    "            flattened_batch = [img.to(device) for sample in batch for img in sample]  # Flatten the nested list\n",
    "            batch_tensor = torch.stack(flattened_batch).squeeze(1)  # Shape: [total_images_in_batch, C, H, W]\n",
    "\n",
    "            # Pass the entire batch through the model\n",
    "            style_vecs = model(batch_tensor)  # Shape: [total_images_in_batch, embedding_dim]\n",
    "\n",
    "            # Reshape the output to match the expected input shape for compute_loss_and_acc\n",
    "            style_vecs = style_vecs.view(batch_size, font_size * group_size, -1) # Shape: [batch_size, group_size, embedding_dim]\n",
    "            \n",
    "            # Compute the loss and accuracy\n",
    "            loss, acc = 0, 0\n",
    "            for i in range(batch_size):\n",
    "                sample_loss, sample_acc = compute_loss_and_acc(style_vecs[i], group_size)\n",
    "                loss += sample_loss\n",
    "                acc += sample_acc\n",
    "\n",
    "            loss /= batch_size\n",
    "            acc /= batch_size\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "            progress_bar.set_postfix(loss=loss.item(), acc=acc)\n",
    "        progress_bar.close()\n",
    "\n",
    "    return total_loss / len(data_loader), total_acc / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for the image 数据\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 转为张量\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # 将单通道图像复制为3通道\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet 标准化\n",
    "])\n",
    "\n",
    "# 定义一个简单的 Dataset 类来处理样本\n",
    "class FontDataset(Dataset):\n",
    "    def __init__(self, batchs, transform=None):\n",
    "        self.batchs = batchs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batchs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.batchs[idx]\n",
    "        if self.transform:\n",
    "            batch = [[self.transform(img) for img in inner_list] for inner_list in batch]\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器（只包含 model 参数）\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=4e-4, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "# 迭代次数，可根据需求调整\n",
    "num_epochs = 16\n",
    "epoch_length = 64  # 每个 epoch 中的 batch 个数\n",
    "\n",
    "# 假设每次采样返回的样本中，同一字体的样本数等于 sample_cnt，此处作为 group_size\n",
    "font_cnt = 4\n",
    "sample_cnt = 4\n",
    "batch_size = 16  # 每个批次的样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Collecting val samples:   0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Collecting val samples: 100%|██████████| 128/128 [00:11<00:00, 11.42it/s]\n",
      "Epoch 1 - Collecting train samples: 100%|██████████| 1024/1024 [01:31<00:00, 11.22it/s]\n",
      "Epoch 1 - Training: 100%|██████████| 64/64 [12:27<00:00, 11.68s/it, acc=0.918, loss=0.202]\n",
      "Validating: 100%|██████████| 8/8 [00:31<00:00,  3.95s/it, acc=0.783, loss=0.635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16 - Train Loss: 0.3934, Train Acc: 0.8846, Val Loss: 0.6546, Val Acc: 0.7785\n",
      "Model saved to font_style2vec_dot_model(dot)_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Collecting val samples: 100%|██████████| 128/128 [00:12<00:00,  9.97it/s]\n",
      "Epoch 2 - Collecting train samples:   4%|▍         | 42/1024 [00:17<01:43,  9.49it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m\n\u001b[1;32m     21\u001b[0m     train_futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(sample, sampler, font_cnt, sample_cnt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_samples_count)]\n\u001b[0;32m---> 22\u001b[0m     train_samples \u001b[38;5;241m=\u001b[39m [future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(train_futures, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Collecting train samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 将采样结果重新排布为 [epoch_length, batch_size] 的格式\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m     train_futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(sample, sampler, font_cnt, sample_cnt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_samples_count)]\n\u001b[0;32m---> 22\u001b[0m     train_samples \u001b[38;5;241m=\u001b[39m [\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(train_futures, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Collecting train samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 将采样结果重新排布为 [epoch_length, batch_size] 的格式\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m val_samples_count \u001b[38;5;241m=\u001b[39m total_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m  \u001b[38;5;66;03m# 1/8 的数据用于验证\u001b[39;00m\n\u001b[1;32m     15\u001b[0m train_samples_count \u001b[38;5;241m=\u001b[39m total_samples\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     18\u001b[0m     val_futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(sample, sampler, font_cnt, sample_cnt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(val_samples_count)]\n\u001b[1;32m     19\u001b[0m     val_samples \u001b[38;5;241m=\u001b[39m [future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(val_futures, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Collecting val samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def sample(sampler, font_cnt, sample_cnt, sample_source):\n",
    "    sample = sampler.sample(font_cnt=font_cnt, sample_cnt=sample_cnt, sample_source=sample_source)\n",
    "    return sample\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 收集一个 epoch 所需的所有训练样本\n",
    "    train_samples = []\n",
    "    val_samples = []\n",
    "\n",
    "    # 使用多线程采样所有数据\n",
    "    total_samples = epoch_length * batch_size\n",
    "    val_samples_count = total_samples // 8  # 1/8 的数据用于验证\n",
    "    train_samples_count = total_samples\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=32) as executor:\n",
    "        val_futures = [executor.submit(sample, sampler, font_cnt, sample_cnt, \"test\") for _ in range(val_samples_count)]\n",
    "        val_samples = [future.result() for future in tqdm(val_futures, desc=f\"Epoch {epoch + 1} - Collecting val samples\")]\n",
    "\n",
    "        train_futures = [executor.submit(sample, sampler, font_cnt, sample_cnt, \"train\") for _ in range(train_samples_count)]\n",
    "        train_samples = [future.result() for future in tqdm(train_futures, desc=f\"Epoch {epoch + 1} - Collecting train samples\")]\n",
    "\n",
    "    # 将采样结果重新排布为 [epoch_length, batch_size] 的格式\n",
    "    train_batches = []\n",
    "    for i in range(epoch_length):\n",
    "        batch_samples = train_samples[i * batch_size:(i + 1) * batch_size]\n",
    "        train_batches.append(batch_samples)\n",
    "\n",
    "    val_batches = []\n",
    "    val_length = len(val_samples) // batch_size\n",
    "    for i in range(val_length):\n",
    "        batch_samples = val_samples[i * batch_size:(i + 1) * batch_size]\n",
    "        val_batches.append(batch_samples)\n",
    "\n",
    "    # 创建训练集 Dataset 和 DataLoader\n",
    "    train_dataset = FontDataset(train_batches, transform=data_transforms)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # 创建验证集 Dataset 和 DataLoader\n",
    "    val_dataset = FontDataset(val_batches, transform=data_transforms)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    train_loss, train_acc = train_step(model, epoch, train_loader, optimizer, batch_size, font_cnt, sample_cnt)\n",
    "    val_loss, val_acc = validate(model, val_loader, batch_size, font_cnt, sample_cnt)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # 保存模型\n",
    "    model_save_path = f'font_style2vec_dot_model(dot)_epoch_{epoch + 1}.pth'\n",
    "    torch.save(model, model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
