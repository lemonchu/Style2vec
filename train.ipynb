{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import FontSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 配置字体相关路径\n",
    "fonts_dir = \"./font_ds/fonts\"            # 字体文件夹路径\n",
    "text_file = \"./font_ds/cleaned_text.txt\" # 文本文件路径\n",
    "chars_file = \"./font_ds/chars.txt\"                  # 常用字文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading fonts and rendering characters: 100%|██████████| 512/512 [15:01<00:00,  1.76s/it]\n",
      "Loading fonts and rendering characters: 100%|██████████| 56/56 [01:44<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# 初始化 FontSampler，同时会将字体分为 train/test 两类\n",
    "sampler = FontSampler(fonts_dir, text_file, chars_file, font_size=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------------------------\n",
    "# 定义模型并迁移到设备上，输出嵌入向量\n",
    "model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT).to(device)\n",
    "embedding_dim = 128  # 输出嵌入向量的维度\n",
    "hidden_dim = 256     # 隐藏层维度\n",
    "\n",
    "# 修改最后全连接层，直接输出嵌入向量\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, hidden_dim),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(hidden_dim, hidden_dim),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(hidden_dim, embedding_dim)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_loss_and_acc(style_vecs, group_size):\n",
    "    \"\"\"\n",
    "    计算交叉熵损失和准确率。\n",
    "    对于每一行，重新生成一个 tensor，直接去除对角线（即自身的分数）。\n",
    "\n",
    "    :param style_vecs: 向量序列，由模型生成，形状为 [N, embedding_dim]\n",
    "    :param group_size: 每组的大小\n",
    "    :return: loss 和 acc\n",
    "    \"\"\"\n",
    "    similarity_matrix = torch.matmul(style_vecs, style_vecs.T)  # shape: [N, N]\n",
    "    N = similarity_matrix.size(0)\n",
    "    losses = []\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        row = similarity_matrix[i]  # shape: [N]\n",
    "        # 重新构造一个 tensor，去除自身的分数（第 i 个元素）\n",
    "        new_row = torch.cat((row[:i], row[i+1:]))  # shape: [N-1]\n",
    "        \n",
    "        # 对新 row 计算 log_softmax\n",
    "        log_softmax_row = F.log_softmax(new_row, dim=0)\n",
    "        \n",
    "        # 构造目标分布：对于当前行所属的组（group_start 到 group_end-1），除去自身，每个目标均为 1/(group_size-1)\n",
    "        target = torch.zeros_like(new_row)\n",
    "        group_start = (i // group_size) * group_size\n",
    "        group_end = group_start + group_size -1\n",
    "        target[group_start:group_end] = 1.0 / (group_size - 1)\n",
    "        \n",
    "        # 计算 KL 散度损失\n",
    "        row_loss = F.kl_div(log_softmax_row, target, reduction='sum')\n",
    "        losses.append(row_loss)\n",
    "\n",
    "        # 计算准确率：\n",
    "        # 从 new_row 选取 top-(group_size-1)，如果这些位置对应的原始索引均落在同一组中，则算作正确\n",
    "        topk_indices = new_row.topk(group_size - 1).indices\n",
    "        correct_in_row = ((topk_indices >= group_start) & (topk_indices < group_end)).sum().item()\n",
    "        correct += correct_in_row\n",
    "\n",
    "    loss = torch.stack(losses).mean()\n",
    "    acc = correct / ((group_size - 1) * N)\n",
    "\n",
    "    # 以 1e-3 的概率展示相似度矩阵 softmax\n",
    "    if random.random() < 1e-3:\n",
    "        softmax_matrix = F.softmax(similarity_matrix, dim=1)\n",
    "        print(f\"Softmax Matrix: {softmax_matrix}\")\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 训练和验证步骤（loss 基于 word2vec 风格的 compute_loss）\n",
    "def train_step(model, epoch, data_loader, optimizer, batch_size, font_size, group_size):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    progress_bar = tqdm(data_loader, desc=f'Epoch {epoch + 1} - Training', leave=True)\n",
    "    for batch in progress_bar:\n",
    "        # Flatten the batch into a single tensor\n",
    "        flattened_batch = [img.to(device) for sample in batch for img in sample]  # Flatten the nested list\n",
    "        batch_tensor = torch.stack(flattened_batch).squeeze(1)  # Shape: [total_images_in_batch, C, H, W]\n",
    "\n",
    "        # Pass the entire batch through the model\n",
    "        style_vecs = model(batch_tensor)  # Shape: [total_images_in_batch, embedding_dim]\n",
    "\n",
    "        # Reshape the output to match the expected input shape for compute_loss_and_acc\n",
    "        style_vecs = style_vecs.view(batch_size, font_size * group_size, -1)  # Shape: [batch_size, group_size, embedding_dim]\n",
    "        \n",
    "        # Compute the loss and accuracy\n",
    "        loss, acc = 0, 0\n",
    "        for i in range(batch_size):\n",
    "            sample_loss, sample_acc = compute_loss_and_acc(style_vecs[i], group_size)\n",
    "            loss += sample_loss\n",
    "            acc += sample_acc\n",
    "\n",
    "        loss /= batch_size\n",
    "        acc /= batch_size\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "        progress_bar.set_postfix(loss=loss.item(), acc=acc)\n",
    "    progress_bar.close()\n",
    "\n",
    "    return total_loss / len(data_loader), total_acc / len(data_loader)\n",
    "\n",
    "def validate(model, data_loader, batch_size, font_size, group_size):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc=\"Validating\", leave=True)\n",
    "        for batch in progress_bar:\n",
    "            # Flatten the batch into a single tensor\n",
    "            flattened_batch = [img.to(device) for sample in batch for img in sample]  # Flatten the nested list\n",
    "            batch_tensor = torch.stack(flattened_batch).squeeze(1)  # Shape: [total_images_in_batch, C, H, W]\n",
    "\n",
    "            # Pass the entire batch through the model\n",
    "            style_vecs = model(batch_tensor)  # Shape: [total_images_in_batch, embedding_dim]\n",
    "\n",
    "            # Reshape the output to match the expected input shape for compute_loss_and_acc\n",
    "            style_vecs = style_vecs.view(batch_size, font_size * group_size, -1) # Shape: [batch_size, group_size, embedding_dim]\n",
    "            \n",
    "            # Compute the loss and accuracy\n",
    "            loss, acc = 0, 0\n",
    "            for i in range(batch_size):\n",
    "                sample_loss, sample_acc = compute_loss_and_acc(style_vecs[i], group_size)\n",
    "                loss += sample_loss\n",
    "                acc += sample_acc\n",
    "\n",
    "            loss /= batch_size\n",
    "            acc /= batch_size\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "            progress_bar.set_postfix(loss=loss.item(), acc=acc)\n",
    "        progress_bar.close()\n",
    "\n",
    "    return total_loss / len(data_loader), total_acc / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for the image 数据\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 转为张量\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # 将单通道图像复制为3通道\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet 标准化\n",
    "])\n",
    "\n",
    "# 定义一个简单的 Dataset 类来处理样本\n",
    "class FontDataset(Dataset):\n",
    "    def __init__(self, batchs, transform=None):\n",
    "        self.batchs = batchs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batchs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.batchs[idx]\n",
    "        if self.transform:\n",
    "            batch = [[self.transform(img) for img in inner_list] for inner_list in batch]\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器（只包含 model 参数）\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=4e-4, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "# 迭代次数，可根据需求调整\n",
    "num_epochs = 16\n",
    "epoch_length = 64  # 每个 epoch 中的 batch 个数\n",
    "\n",
    "# 假设每次采样返回的样本中，同一字体的样本数等于 sample_cnt，此处作为 group_size\n",
    "font_cnt = 4\n",
    "sample_cnt = 4\n",
    "batch_size = 16  # 每个批次的样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Collecting val samples:   0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Collecting val samples: 100%|██████████| 128/128 [00:07<00:00, 17.65it/s]\n",
      "Epoch 1 - Collecting train samples: 100%|██████████| 1024/1024 [01:00<00:00, 16.96it/s]\n",
      "Epoch 1 - Training: 100%|██████████| 64/64 [00:57<00:00,  1.11it/s, acc=0.974, loss=0.14]  \n",
      "Validating: 100%|██████████| 8/8 [00:06<00:00,  1.19it/s, acc=0.961, loss=0.152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16 - Train Loss: 0.2475, Train Acc: 0.9293, Val Loss: 0.1572, Val Acc: 0.9665\n",
      "Model saved to font_identifier_model_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Collecting val samples: 100%|██████████| 128/128 [00:07<00:00, 17.57it/s]\n",
      "Epoch 2 - Collecting train samples: 100%|██████████| 1024/1024 [01:01<00:00, 16.77it/s]\n",
      "Epoch 2 - Training:  45%|████▌     | 29/64 [00:24<00:29,  1.18it/s, acc=0.947, loss=0.161] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Matrix: tensor([[1.9576e-01, 8.8313e-02, 2.0858e-01, 1.7127e-01, 2.5257e-10, 1.5003e-10,\n",
      "         1.7081e-10, 1.8253e-10, 9.8909e-02, 1.4360e-01, 4.3086e-02, 5.0487e-02,\n",
      "         7.7019e-10, 1.7302e-09, 7.1675e-10, 4.1060e-10],\n",
      "        [1.2550e-01, 1.2346e-01, 1.7429e-01, 1.5707e-01, 1.4157e-10, 8.4904e-11,\n",
      "         9.5129e-11, 1.0286e-10, 1.0988e-01, 1.5171e-01, 6.8614e-02, 8.9479e-02,\n",
      "         4.8718e-10, 1.1093e-09, 4.4785e-10, 2.5418e-10],\n",
      "        [1.6233e-01, 9.5450e-02, 2.0116e-01, 1.7544e-01, 1.3371e-10, 7.8616e-11,\n",
      "         9.0476e-11, 9.7346e-11, 1.0504e-01, 1.4882e-01, 4.8687e-02, 6.3072e-02,\n",
      "         4.7123e-10, 1.0940e-09, 4.3772e-10, 2.4378e-10],\n",
      "        [1.4313e-01, 9.2372e-02, 1.8839e-01, 2.0644e-01, 2.0576e-10, 1.1735e-10,\n",
      "         1.3182e-10, 1.4593e-10, 1.1490e-01, 1.4129e-01, 3.9261e-02, 7.4220e-02,\n",
      "         3.9739e-10, 8.5969e-10, 3.7690e-10, 2.1075e-10],\n",
      "        [1.9420e-08, 7.6594e-09, 1.3209e-08, 1.8930e-08, 3.1207e-01, 2.7408e-01,\n",
      "         1.7796e-01, 2.3558e-01, 1.3896e-08, 9.8132e-09, 4.2100e-09, 8.3207e-09,\n",
      "         6.5952e-05, 1.4295e-05, 8.9194e-05, 1.4093e-04],\n",
      "        [1.2410e-08, 4.9418e-09, 8.3554e-09, 1.1615e-08, 2.9486e-01, 2.8458e-01,\n",
      "         1.8215e-01, 2.3785e-01, 8.5774e-09, 6.0681e-09, 2.8012e-09, 5.1236e-09,\n",
      "         1.1940e-04, 2.6098e-05, 1.5989e-04, 2.5541e-04],\n",
      "        [2.1332e-08, 8.3600e-09, 1.4518e-08, 1.9699e-08, 2.8906e-01, 2.7502e-01,\n",
      "         1.9297e-01, 2.4219e-01, 1.4811e-08, 1.0779e-08, 4.9795e-09, 8.9541e-09,\n",
      "         1.6104e-04, 3.7575e-05, 2.1558e-04, 3.3972e-04],\n",
      "        [1.7569e-08, 6.9668e-09, 1.2039e-08, 1.6807e-08, 2.9490e-01, 2.7677e-01,\n",
      "         1.8666e-01, 2.4108e-01, 1.2445e-08, 8.8671e-09, 3.9728e-09, 7.5090e-09,\n",
      "         1.2425e-04, 2.7997e-05, 1.6767e-04, 2.6318e-04],\n",
      "        [1.2827e-01, 1.0026e-01, 1.7503e-01, 1.7828e-01, 2.3438e-10, 1.3447e-10,\n",
      "         1.5379e-10, 1.6767e-10, 1.1938e-01, 1.5729e-01, 5.4382e-02, 8.7112e-02,\n",
      "         4.7467e-10, 1.0146e-09, 4.4748e-10, 2.5332e-10],\n",
      "        [1.3320e-01, 9.9019e-02, 1.7736e-01, 1.5681e-01, 1.1838e-10, 6.8046e-11,\n",
      "         8.0057e-11, 8.5450e-11, 1.1250e-01, 1.7379e-01, 6.5402e-02, 8.1909e-02,\n",
      "         3.3364e-10, 7.4341e-10, 3.1089e-10, 1.7488e-10],\n",
      "        [1.0809e-01, 1.2113e-01, 1.5694e-01, 1.1786e-01, 1.3736e-10, 8.4960e-11,\n",
      "         1.0003e-10, 1.0355e-10, 1.0520e-01, 1.7689e-01, 1.1678e-01, 9.7110e-02,\n",
      "         7.5018e-10, 1.7492e-09, 6.7606e-10, 3.9090e-10],\n",
      "        [9.2250e-02, 1.1505e-01, 1.4808e-01, 1.6227e-01, 1.9774e-10, 1.1318e-10,\n",
      "         1.3100e-10, 1.4255e-10, 1.2274e-01, 1.6135e-01, 7.0729e-02, 1.2753e-01,\n",
      "         3.8962e-10, 8.2792e-10, 3.6705e-10, 2.0847e-10],\n",
      "        [1.9115e-06, 8.5079e-07, 1.5027e-06, 1.1801e-06, 2.1288e-03, 3.5823e-03,\n",
      "         3.2001e-03, 3.2037e-03, 9.0841e-07, 8.9270e-07, 7.4213e-07, 5.2920e-07,\n",
      "         2.5835e-01, 2.4495e-01, 2.4505e-01, 2.3953e-01],\n",
      "        [4.3885e-06, 1.9799e-06, 3.5653e-06, 2.6091e-06, 4.7156e-04, 8.0025e-04,\n",
      "         7.6312e-04, 7.3775e-04, 1.9845e-06, 2.0328e-06, 1.7684e-06, 1.1493e-06,\n",
      "         2.5034e-01, 3.2699e-01, 2.2347e-01, 1.9640e-01],\n",
      "        [1.8643e-06, 8.1969e-07, 1.4629e-06, 1.1730e-06, 3.0173e-03, 5.0277e-03,\n",
      "         4.4898e-03, 4.5310e-03, 8.9751e-07, 8.7177e-07, 7.0093e-07, 5.2249e-07,\n",
      "         2.5682e-01, 2.2916e-01, 2.5017e-01, 2.4677e-01],\n",
      "        [1.0818e-06, 4.7123e-07, 8.2526e-07, 6.6440e-07, 4.8289e-03, 8.1350e-03,\n",
      "         7.1666e-03, 7.2039e-03, 5.1466e-07, 4.9673e-07, 4.1052e-07, 3.0059e-07,\n",
      "         2.5428e-01, 2.0401e-01, 2.4996e-01, 2.6441e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 64/64 [00:54<00:00,  1.16it/s, acc=0.978, loss=0.103] \n",
      "Validating: 100%|██████████| 8/8 [00:05<00:00,  1.35it/s, acc=0.962, loss=0.145] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/16 - Train Loss: 0.1295, Train Acc: 0.9750, Val Loss: 0.1224, Val Acc: 0.9811\n",
      "Model saved to font_identifier_model_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Collecting val samples: 100%|██████████| 128/128 [00:07<00:00, 17.92it/s]\n",
      "Epoch 3 - Collecting train samples: 100%|██████████| 1024/1024 [00:58<00:00, 17.44it/s]\n",
      "Epoch 3 - Training:  39%|███▉      | 25/64 [00:18<00:28,  1.35it/s, acc=0.988, loss=0.0916]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Matrix: tensor([[3.2207e-01, 2.5854e-01, 2.6400e-01, 1.5463e-01, 9.4547e-05, 4.9074e-05,\n",
      "         7.5617e-05, 6.8757e-05, 1.1101e-04, 7.9784e-05, 1.1925e-04, 1.6625e-04,\n",
      "         5.9090e-08, 4.0055e-08, 1.4861e-07, 1.4812e-07],\n",
      "        [2.6380e-01, 3.9661e-01, 1.6868e-01, 1.7051e-01, 2.9766e-05, 1.4687e-05,\n",
      "         2.1886e-05, 2.2445e-05, 9.0697e-05, 4.5471e-05, 8.3125e-05, 8.8375e-05,\n",
      "         5.2768e-08, 4.7921e-08, 1.1188e-07, 1.0992e-07],\n",
      "        [2.7659e-01, 1.7321e-01, 3.7681e-01, 1.7076e-01, 4.3381e-04, 2.4353e-04,\n",
      "         3.6635e-04, 3.8506e-04, 2.1677e-04, 2.0122e-04, 3.2407e-04, 4.6482e-04,\n",
      "         1.1204e-07, 5.9431e-08, 2.5599e-07, 2.6931e-07],\n",
      "        [2.2592e-01, 2.4415e-01, 2.3812e-01, 2.8701e-01, 4.5842e-05, 2.6040e-05,\n",
      "         3.7777e-05, 4.9326e-05, 1.1756e-03, 4.8978e-04, 1.4091e-03, 1.5729e-03,\n",
      "         3.7559e-08, 2.5053e-08, 7.2682e-08, 8.1831e-08],\n",
      "        [3.5013e-05, 1.0803e-05, 1.5333e-04, 1.1620e-05, 2.5684e-01, 2.7865e-01,\n",
      "         2.3615e-01, 2.2799e-01, 4.2102e-08, 2.7731e-07, 1.4988e-07, 2.4597e-07,\n",
      "         4.7239e-05, 1.6843e-05, 4.8199e-05, 4.0866e-05],\n",
      "        [1.5409e-05, 4.5196e-06, 7.2983e-05, 5.5965e-06, 2.3626e-01, 3.0092e-01,\n",
      "         2.2438e-01, 2.3825e-01, 2.6152e-08, 1.5694e-07, 1.0128e-07, 1.6884e-07,\n",
      "         2.8519e-05, 1.0144e-05, 2.6678e-05, 2.2675e-05],\n",
      "        [2.9562e-05, 8.3854e-06, 1.3670e-04, 1.0108e-05, 2.4930e-01, 2.7937e-01,\n",
      "         2.4237e-01, 2.2861e-01, 5.5313e-08, 3.9106e-07, 1.9985e-07, 3.3762e-07,\n",
      "         5.0806e-05, 1.6686e-05, 5.3312e-05, 4.6190e-05],\n",
      "        [2.5420e-05, 8.1326e-06, 1.3588e-04, 1.2482e-05, 2.2761e-01, 2.8052e-01,\n",
      "         2.1619e-01, 2.7541e-01, 8.6491e-08, 4.6225e-07, 3.6204e-07, 5.6284e-07,\n",
      "         2.7494e-05, 9.7560e-06, 2.3916e-05, 2.1483e-05],\n",
      "        [1.3259e-04, 1.0617e-04, 2.4711e-04, 9.6103e-04, 1.3579e-07, 9.9479e-08,\n",
      "         1.6899e-07, 2.7942e-07, 3.2902e-01, 1.3828e-01, 2.8695e-01, 2.4430e-01,\n",
      "         3.4549e-08, 1.7493e-08, 4.3432e-08, 7.8204e-08],\n",
      "        [1.5424e-04, 8.6153e-05, 3.7128e-04, 6.4807e-04, 1.4477e-06, 9.6625e-07,\n",
      "         1.9338e-06, 2.4171e-06, 2.2383e-01, 3.9561e-01, 1.9470e-01, 1.8459e-01,\n",
      "         1.3076e-06, 4.8822e-07, 1.9230e-06, 3.5716e-06],\n",
      "        [1.2559e-04, 8.5795e-05, 3.2574e-04, 1.0157e-03, 4.2624e-07, 3.3968e-07,\n",
      "         5.3835e-07, 1.0313e-06, 2.5302e-01, 1.0606e-01, 3.3595e-01, 3.0341e-01,\n",
      "         2.7168e-08, 1.2216e-08, 3.1184e-08, 5.5314e-08],\n",
      "        [1.8180e-04, 9.4717e-05, 4.8516e-04, 1.1773e-03, 7.2635e-07, 5.8803e-07,\n",
      "         9.4442e-07, 1.6648e-06, 2.2368e-01, 1.0442e-01, 3.1506e-01, 3.5490e-01,\n",
      "         2.5051e-08, 1.0104e-08, 3.2145e-08, 5.5484e-08],\n",
      "        [7.5203e-08, 6.5819e-08, 1.3610e-07, 3.2717e-08, 1.6234e-04, 1.1559e-04,\n",
      "         1.6539e-04, 9.4645e-05, 3.6815e-08, 8.6081e-07, 3.2832e-08, 2.9155e-08,\n",
      "         3.3678e-01, 1.7252e-01, 2.4128e-01, 2.4889e-01],\n",
      "        [9.6630e-08, 1.1330e-07, 1.3684e-07, 4.1367e-08, 1.0972e-04, 7.7939e-05,\n",
      "         1.0297e-04, 6.3660e-05, 3.5333e-08, 6.0925e-07, 2.7984e-08, 2.2288e-08,\n",
      "         3.2701e-01, 2.8357e-01, 1.9921e-01, 1.8986e-01],\n",
      "        [2.1615e-07, 1.5948e-07, 3.5536e-07, 7.2355e-08, 1.8930e-04, 1.2357e-04,\n",
      "         1.9834e-04, 9.4086e-05, 5.2889e-08, 1.4467e-06, 4.3067e-08, 4.2753e-08,\n",
      "         2.7573e-01, 1.2010e-01, 3.0015e-01, 3.0340e-01],\n",
      "        [2.0832e-07, 1.5152e-07, 3.6151e-07, 7.8773e-08, 1.5520e-04, 1.0156e-04,\n",
      "         1.6617e-04, 8.1726e-05, 9.2088e-08, 2.5984e-06, 7.3870e-08, 7.1358e-08,\n",
      "         2.7504e-01, 1.1068e-01, 2.9339e-01, 3.2038e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training:  53%|█████▎    | 34/64 [00:26<00:24,  1.20it/s, acc=0.991, loss=0.108] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Matrix: tensor([[3.2002e-01, 3.0399e-01, 1.0128e-01, 2.7456e-01, 3.0619e-06, 1.6409e-06,\n",
      "         1.6144e-06, 2.2358e-06, 8.2778e-06, 2.4352e-06, 8.1158e-05, 2.5181e-05,\n",
      "         1.2063e-05, 3.3151e-06, 1.2384e-06, 5.0670e-06],\n",
      "        [2.5542e-01, 3.2707e-01, 1.1605e-01, 3.0138e-01, 2.4353e-06, 1.3084e-06,\n",
      "         1.2677e-06, 2.0408e-06, 2.0951e-06, 7.6884e-07, 2.2726e-05, 6.7122e-06,\n",
      "         2.2199e-05, 5.7976e-06, 2.1423e-06, 8.5357e-06],\n",
      "        [1.8862e-01, 2.5722e-01, 3.5950e-01, 1.9456e-01, 2.8478e-06, 2.0444e-06,\n",
      "         1.5829e-06, 2.6431e-06, 4.0983e-06, 1.3932e-06, 1.1718e-05, 5.6430e-06,\n",
      "         3.7491e-05, 1.0779e-05, 8.7132e-06, 1.3723e-05],\n",
      "        [2.5117e-01, 3.2815e-01, 9.5577e-02, 3.2501e-01, 2.4741e-06, 1.2859e-06,\n",
      "         1.3127e-06, 2.0693e-06, 1.8653e-06, 7.0365e-07, 2.4028e-05, 6.6457e-06,\n",
      "         2.8782e-05, 7.6800e-06, 2.4480e-06, 1.1615e-05],\n",
      "        [3.3633e-06, 3.1838e-06, 1.6797e-06, 2.9707e-06, 2.8595e-01, 2.1778e-01,\n",
      "         2.7958e-01, 2.1466e-01, 5.7845e-05, 1.5795e-03, 1.5546e-04, 2.3347e-04,\n",
      "         2.4213e-08, 4.0675e-08, 4.6475e-08, 4.8442e-08],\n",
      "        [1.9492e-06, 1.8498e-06, 1.3041e-06, 1.6697e-06, 2.3551e-01, 2.6255e-01,\n",
      "         2.9021e-01, 2.1057e-01, 3.7424e-05, 9.7318e-04, 5.4172e-05, 9.8073e-05,\n",
      "         3.3528e-08, 6.3844e-08, 8.4066e-08, 7.5179e-08],\n",
      "        [1.5626e-06, 1.4604e-06, 8.2270e-07, 1.3889e-06, 2.4636e-01, 2.3647e-01,\n",
      "         3.1014e-01, 2.0598e-01, 2.9501e-05, 8.4522e-04, 6.3224e-05, 1.0333e-04,\n",
      "         2.7673e-08, 5.4393e-08, 6.3259e-08, 6.5638e-08],\n",
      "        [2.8816e-06, 3.1305e-06, 1.8292e-06, 2.9153e-06, 2.5188e-01, 2.2846e-01,\n",
      "         2.7427e-01, 2.4479e-01, 1.6383e-05, 4.6533e-04, 4.2858e-05, 6.1478e-05,\n",
      "         5.5802e-08, 9.7086e-08, 1.1118e-07, 1.1209e-07],\n",
      "        [5.7112e-06, 1.7204e-06, 1.5183e-06, 1.4067e-06, 3.6332e-05, 2.1736e-05,\n",
      "         2.1028e-05, 8.7697e-06, 4.4030e-01, 2.2434e-01, 9.7046e-02, 2.3821e-01,\n",
      "         5.8968e-10, 4.0152e-10, 6.4857e-10, 5.0771e-10],\n",
      "        [1.5703e-06, 5.9004e-07, 4.8240e-07, 4.9597e-07, 9.2722e-04, 5.2827e-04,\n",
      "         5.6307e-04, 2.3281e-04, 2.0968e-01, 5.2271e-01, 6.8657e-02, 1.9670e-01,\n",
      "         2.3356e-10, 2.1181e-10, 3.6111e-10, 2.6866e-10],\n",
      "        [5.9866e-05, 1.9951e-05, 4.6414e-06, 1.9374e-05, 1.0439e-04, 3.3639e-05,\n",
      "         4.8181e-05, 2.4528e-05, 1.0376e-01, 7.8540e-02, 4.4424e-01, 3.7315e-01,\n",
      "         1.8670e-09, 9.5896e-10, 6.3303e-10, 1.3395e-09],\n",
      "        [1.3577e-05, 4.3073e-06, 1.6338e-06, 3.9168e-06, 1.1460e-04, 4.4515e-05,\n",
      "         5.7560e-05, 2.5718e-05, 1.8616e-01, 1.6447e-01, 2.7275e-01, 3.7635e-01,\n",
      "         5.9704e-10, 3.6680e-10, 3.6460e-10, 4.9433e-10],\n",
      "        [3.4847e-05, 7.6321e-05, 5.8154e-05, 9.0881e-05, 6.3676e-08, 8.1531e-08,\n",
      "         8.2586e-08, 1.2507e-07, 2.4689e-09, 1.0463e-09, 7.3112e-09, 3.1987e-09,\n",
      "         2.7807e-01, 2.9253e-01, 2.1639e-01, 2.1274e-01],\n",
      "        [5.3538e-06, 1.1144e-05, 9.3474e-06, 1.3558e-05, 5.9802e-08, 8.6798e-08,\n",
      "         9.0752e-08, 1.2165e-07, 9.3986e-10, 5.3048e-10, 2.0995e-09, 1.0987e-09,\n",
      "         1.6355e-01, 3.1748e-01, 2.8010e-01, 2.3883e-01],\n",
      "        [1.7574e-06, 3.6183e-06, 6.6398e-06, 3.7974e-06, 6.0044e-08, 1.0043e-07,\n",
      "         9.2747e-08, 1.2241e-07, 1.3340e-09, 7.9473e-10, 1.2179e-09, 9.5964e-10,\n",
      "         1.0631e-01, 2.4613e-01, 4.8686e-01, 1.6068e-01],\n",
      "        [1.1005e-05, 2.2063e-05, 1.6004e-05, 2.7575e-05, 9.5778e-08, 1.3745e-07,\n",
      "         1.4727e-07, 1.8888e-07, 1.5982e-09, 9.0485e-10, 3.9440e-09, 1.9912e-09,\n",
      "         1.5995e-01, 3.2118e-01, 2.4590e-01, 2.7289e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 64/64 [00:50<00:00,  1.27it/s, acc=0.986, loss=0.0865]\n",
      "Validating: 100%|██████████| 8/8 [00:05<00:00,  1.42it/s, acc=0.993, loss=0.0759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/16 - Train Loss: 0.1011, Train Acc: 0.9843, Val Loss: 0.0858, Val Acc: 0.9925\n",
      "Model saved to font_identifier_model_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Collecting val samples: 100%|██████████| 128/128 [00:07<00:00, 18.04it/s]\n",
      "Epoch 4 - Collecting train samples: 100%|██████████| 1024/1024 [00:58<00:00, 17.44it/s]\n",
      "Epoch 4 - Training: 100%|██████████| 64/64 [00:54<00:00,  1.18it/s, acc=0.98, loss=0.107]  \n",
      "Validating: 100%|██████████| 8/8 [00:06<00:00,  1.17it/s, acc=0.997, loss=0.0811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/16 - Train Loss: 0.0871, Train Acc: 0.9872, Val Loss: 0.1006, Val Acc: 0.9819\n",
      "Model saved to font_identifier_model_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Collecting val samples: 100%|██████████| 128/128 [00:08<00:00, 15.40it/s]\n",
      "Epoch 5 - Collecting train samples: 100%|██████████| 1024/1024 [00:58<00:00, 17.56it/s]\n",
      "Epoch 5 - Training:  19%|█▉        | 12/64 [00:10<00:42,  1.24it/s, acc=0.99, loss=0.09]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Matrix: tensor([[3.4460e-01, 1.8739e-01, 1.8101e-01, 2.8560e-01, 5.4291e-06, 6.9752e-06,\n",
      "         7.9929e-06, 4.7367e-06, 5.9006e-05, 4.5699e-04, 7.2618e-04, 1.2608e-04,\n",
      "         3.5983e-10, 8.3492e-10, 1.3523e-09, 8.3615e-10],\n",
      "        [2.0013e-01, 3.7291e-01, 1.6807e-01, 2.5785e-01, 8.0464e-05, 1.0863e-04,\n",
      "         1.0898e-04, 6.0829e-05, 4.1907e-05, 2.2860e-04, 3.8977e-04, 3.7377e-05,\n",
      "         4.8574e-09, 1.0523e-08, 1.9433e-08, 1.1677e-08],\n",
      "        [1.9463e-01, 1.6920e-01, 3.1824e-01, 3.1234e-01, 2.0333e-05, 2.4139e-05,\n",
      "         2.5874e-05, 1.5177e-05, 2.7567e-04, 1.7891e-03, 3.0854e-03, 3.5905e-04,\n",
      "         2.9364e-09, 6.0109e-09, 8.3580e-09, 4.4968e-09],\n",
      "        [2.2749e-01, 1.9231e-01, 2.3138e-01, 3.4774e-01, 1.9288e-05, 2.3768e-05,\n",
      "         2.6419e-05, 1.4696e-05, 3.8347e-05, 3.4069e-04, 5.6367e-04, 5.7540e-05,\n",
      "         7.5577e-10, 1.7755e-09, 2.4281e-09, 1.3345e-09],\n",
      "        [6.2361e-06, 8.6543e-05, 2.1722e-05, 2.7815e-05, 2.6878e-01, 2.5007e-01,\n",
      "         2.7157e-01, 2.0943e-01, 6.9343e-07, 2.6169e-06, 2.4953e-06, 6.2946e-08,\n",
      "         1.3331e-06, 5.1558e-07, 7.1868e-07, 5.1480e-07],\n",
      "        [8.4474e-06, 1.2318e-04, 2.7189e-05, 3.6138e-05, 2.6366e-01, 2.5681e-01,\n",
      "         2.7430e-01, 2.0503e-01, 6.8307e-07, 2.5449e-06, 2.4634e-06, 6.4401e-08,\n",
      "         1.4103e-06, 5.8166e-07, 8.3662e-07, 6.0423e-07],\n",
      "        [8.7319e-06, 1.1148e-04, 2.6290e-05, 3.6234e-05, 2.5828e-01, 2.4744e-01,\n",
      "         2.8190e-01, 2.1219e-01, 6.8370e-07, 2.9958e-06, 2.7624e-06, 7.1141e-08,\n",
      "         6.5517e-07, 2.5868e-07, 3.6525e-07, 2.6465e-07],\n",
      "        [6.7512e-06, 8.1181e-05, 2.0119e-05, 2.6296e-05, 2.5987e-01, 2.4130e-01,\n",
      "         2.7684e-01, 2.2184e-01, 9.7572e-07, 3.8743e-06, 3.4568e-06, 9.8053e-08,\n",
      "         9.2662e-07, 3.3352e-07, 4.7843e-07, 3.5709e-07],\n",
      "        [8.0990e-05, 5.3860e-05, 3.5191e-04, 6.6080e-05, 8.2861e-07, 7.7416e-07,\n",
      "         8.5900e-07, 9.3963e-07, 2.9341e-01, 2.2570e-01, 2.4249e-01, 2.3785e-01,\n",
      "         1.0327e-07, 4.2791e-08, 8.1192e-08, 6.3404e-08],\n",
      "        [3.4168e-04, 1.6004e-04, 1.2441e-03, 3.1980e-04, 1.7034e-06, 1.5711e-06,\n",
      "         2.0503e-06, 2.0323e-06, 1.2294e-01, 3.6969e-01, 3.4429e-01, 1.6101e-01,\n",
      "         4.2043e-09, 1.9466e-09, 3.0641e-09, 2.1173e-09],\n",
      "        [5.4165e-04, 2.7222e-04, 2.1404e-03, 5.2783e-04, 1.6203e-06, 1.5172e-06,\n",
      "         1.8861e-06, 1.8090e-06, 1.3177e-01, 3.4347e-01, 3.5945e-01, 1.6182e-01,\n",
      "         6.8503e-09, 3.5503e-09, 5.6753e-09, 3.8106e-09],\n",
      "        [1.2602e-04, 3.4982e-05, 3.3378e-04, 7.2206e-05, 5.4775e-08, 5.3153e-08,\n",
      "         6.5090e-08, 6.8763e-08, 1.7321e-01, 2.1525e-01, 2.1684e-01, 3.9414e-01,\n",
      "         5.4799e-09, 3.0184e-09, 5.0577e-09, 3.9967e-09],\n",
      "        [4.9665e-10, 6.2776e-09, 3.7694e-09, 1.3096e-09, 1.6019e-06, 1.6073e-06,\n",
      "         8.2776e-07, 8.9733e-07, 1.0384e-07, 7.7613e-09, 1.2676e-08, 7.5671e-09,\n",
      "         2.8178e-01, 2.1412e-01, 2.4372e-01, 2.6037e-01],\n",
      "        [9.6495e-10, 1.1388e-08, 6.4611e-09, 2.5762e-09, 5.1877e-07, 5.5509e-07,\n",
      "         2.7366e-07, 2.7044e-07, 3.6031e-08, 3.0090e-09, 5.5012e-09, 3.4901e-09,\n",
      "         1.7929e-01, 2.5659e-01, 2.7761e-01, 2.8651e-01],\n",
      "        [1.2136e-09, 1.6331e-08, 6.9763e-09, 2.7358e-09, 5.6152e-07, 6.1998e-07,\n",
      "         3.0005e-07, 3.0125e-07, 5.3087e-08, 3.6779e-09, 6.8286e-09, 4.5412e-09,\n",
      "         1.5847e-01, 2.1557e-01, 2.9834e-01, 3.2762e-01],\n",
      "        [6.7735e-10, 8.8572e-09, 3.3880e-09, 1.3572e-09, 3.6307e-07, 4.0418e-07,\n",
      "         1.9624e-07, 2.0296e-07, 3.7421e-08, 2.2940e-09, 4.1386e-09, 3.2392e-09,\n",
      "         1.5282e-01, 2.0082e-01, 2.9573e-01, 3.5063e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training: 100%|██████████| 64/64 [00:52<00:00,  1.21it/s, acc=0.999, loss=0.0515]\n",
      "Validating: 100%|██████████| 8/8 [00:06<00:00,  1.25it/s, acc=0.999, loss=0.06]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/16 - Train Loss: 0.0892, Train Acc: 0.9853, Val Loss: 0.0779, Val Acc: 0.9941\n",
      "Model saved to font_identifier_model_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Collecting val samples: 100%|██████████| 128/128 [00:07<00:00, 17.99it/s]\n",
      "Epoch 6 - Collecting train samples: 100%|██████████| 1024/1024 [00:58<00:00, 17.42it/s]\n",
      "Epoch 6 - Training: 100%|██████████| 64/64 [00:52<00:00,  1.22it/s, acc=0.991, loss=0.0545]\n",
      "Validating:  75%|███████▌  | 6/8 [00:04<00:01,  1.23it/s, acc=0.996, loss=0.0606]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Matrix: tensor([[6.1510e-01, 1.9490e-01, 1.2877e-02, 1.7074e-01, 1.1983e-10, 1.6794e-10,\n",
      "         7.3972e-11, 1.0407e-10, 5.0285e-04, 1.8778e-04, 1.6462e-04, 2.1762e-04,\n",
      "         1.8255e-04, 1.1173e-03, 3.7901e-03, 2.1773e-04],\n",
      "        [3.5081e-01, 3.3212e-01, 5.6566e-02, 2.2712e-01, 4.9060e-10, 4.7058e-10,\n",
      "         2.2267e-10, 3.8917e-10, 3.2835e-03, 1.4842e-03, 1.3108e-03, 1.5530e-03,\n",
      "         1.0476e-03, 4.6095e-03, 1.9061e-02, 1.0387e-03],\n",
      "        [1.4661e-02, 3.5780e-02, 4.9742e-01, 1.1557e-01, 5.1818e-08, 2.6640e-08,\n",
      "         1.9709e-08, 4.1065e-08, 4.4653e-03, 2.2320e-03, 2.1637e-03, 1.7489e-03,\n",
      "         4.4907e-02, 7.0920e-02, 1.5970e-01, 5.0439e-02],\n",
      "        [2.1177e-01, 1.5651e-01, 1.2590e-01, 4.6681e-01, 1.5119e-09, 1.1105e-09,\n",
      "         8.2530e-10, 1.1435e-09, 1.4209e-03, 6.1587e-04, 6.0684e-04, 5.6750e-04,\n",
      "         2.9841e-03, 8.9183e-03, 2.0885e-02, 3.0144e-03],\n",
      "        [4.7429e-11, 1.0788e-10, 1.8014e-08, 4.8243e-10, 3.2092e-01, 2.3335e-01,\n",
      "         2.3613e-01, 2.0960e-01, 3.8107e-07, 5.4804e-07, 6.3998e-07, 4.1371e-07,\n",
      "         8.3535e-09, 2.4606e-09, 1.9712e-09, 2.1527e-08],\n",
      "        [7.5799e-11, 1.1800e-10, 1.0561e-08, 4.0409e-10, 2.6610e-01, 3.0258e-01,\n",
      "         2.2756e-01, 2.0375e-01, 2.6884e-07, 3.4649e-07, 3.8345e-07, 2.8372e-07,\n",
      "         4.3098e-09, 1.6992e-09, 1.4224e-09, 1.3184e-08],\n",
      "        [3.4169e-11, 5.7146e-11, 7.9965e-09, 3.0736e-10, 2.7558e-01, 2.3289e-01,\n",
      "         2.7823e-01, 2.1329e-01, 8.6791e-08, 1.1873e-07, 1.3886e-07, 9.1263e-08,\n",
      "         6.2935e-09, 1.8974e-09, 1.1319e-09, 1.6666e-08],\n",
      "        [5.5282e-11, 1.1485e-10, 1.9159e-08, 4.8971e-10, 2.8130e-01, 2.3980e-01,\n",
      "         2.4528e-01, 2.3362e-01, 1.8941e-07, 2.5104e-07, 2.8289e-07, 1.9354e-07,\n",
      "         1.6640e-08, 5.2498e-09, 3.6260e-09, 4.5784e-08],\n",
      "        [2.3282e-04, 8.4463e-04, 1.8159e-03, 5.3042e-04, 4.4578e-07, 2.7579e-07,\n",
      "         8.6994e-08, 1.6510e-07, 2.5239e-01, 2.5595e-01, 2.5168e-01, 2.3650e-01,\n",
      "         3.3096e-06, 5.2541e-06, 4.1932e-05, 4.0611e-06],\n",
      "        [7.6612e-05, 3.3643e-04, 7.9984e-04, 2.0258e-04, 5.6494e-07, 3.1321e-07,\n",
      "         1.0486e-07, 1.9281e-07, 2.2554e-01, 2.6556e-01, 2.6788e-01, 2.3958e-01,\n",
      "         1.4504e-06, 1.9928e-06, 1.5935e-05, 1.6579e-06],\n",
      "        [6.6823e-05, 2.9562e-04, 7.7147e-04, 1.9861e-04, 6.5638e-07, 3.4487e-07,\n",
      "         1.2203e-07, 2.1619e-07, 2.2066e-01, 2.6653e-01, 2.7482e-01, 2.3664e-01,\n",
      "         1.3554e-06, 1.7654e-06, 1.3599e-05, 1.5145e-06],\n",
      "        [9.7468e-05, 3.8644e-04, 6.8801e-04, 2.0492e-04, 4.6815e-07, 2.8154e-07,\n",
      "         8.8486e-08, 1.6318e-07, 2.2877e-01, 2.6300e-01, 2.6109e-01, 2.4574e-01,\n",
      "         1.1450e-06, 1.7118e-06, 1.4296e-05, 1.3383e-06],\n",
      "        [1.1093e-04, 3.5368e-04, 2.3969e-02, 1.4620e-03, 1.2826e-08, 5.8027e-09,\n",
      "         8.2795e-09, 1.9036e-08, 4.3438e-06, 2.1603e-06, 2.0290e-06, 1.5536e-06,\n",
      "         2.7884e-01, 2.5261e-01, 1.7336e-01, 2.6928e-01],\n",
      "        [5.4627e-04, 1.2522e-03, 3.0457e-02, 3.5156e-03, 3.0397e-09, 1.8408e-09,\n",
      "         2.0084e-09, 4.8322e-09, 5.5484e-06, 2.3882e-06, 2.1263e-06, 1.8688e-06,\n",
      "         2.0325e-01, 2.9336e-01, 2.4985e-01, 2.1777e-01],\n",
      "        [1.8446e-03, 5.1540e-03, 6.8269e-02, 8.1952e-03, 2.4240e-09, 1.5338e-09,\n",
      "         1.1926e-09, 3.3223e-09, 4.4078e-05, 1.9009e-05, 1.6305e-05, 1.5536e-05,\n",
      "         1.3884e-01, 2.4870e-01, 3.7815e-01, 1.5075e-01],\n",
      "        [1.2250e-04, 3.2468e-04, 2.4925e-02, 1.3673e-03, 3.0601e-08, 1.6435e-08,\n",
      "         2.0299e-08, 4.8493e-08, 4.9349e-06, 2.2862e-06, 2.0990e-06, 1.6811e-06,\n",
      "         2.4931e-01, 2.5058e-01, 1.7426e-01, 2.9909e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 8/8 [00:06<00:00,  1.23it/s, acc=0.993, loss=0.0705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/16 - Train Loss: 0.0774, Train Acc: 0.9901, Val Loss: 0.0766, Val Acc: 0.9948\n",
      "Model saved to font_identifier_model_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Collecting val samples: 100%|██████████| 128/128 [00:07<00:00, 17.88it/s]\n",
      "Epoch 7 - Collecting train samples: 100%|██████████| 1024/1024 [00:58<00:00, 17.65it/s]\n",
      "Epoch 7 - Training: 100%|██████████| 64/64 [00:54<00:00,  1.17it/s, acc=0.999, loss=0.0495]\n",
      "Validating: 100%|██████████| 8/8 [00:06<00:00,  1.33it/s, acc=0.99, loss=0.0673] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/16 - Train Loss: 0.0717, Train Acc: 0.9919, Val Loss: 0.0793, Val Acc: 0.9863\n",
      "Model saved to font_identifier_model_epoch_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Collecting val samples: 100%|██████████| 128/128 [00:07<00:00, 17.71it/s]\n",
      "Epoch 8 - Collecting train samples: 100%|██████████| 1024/1024 [00:58<00:00, 17.60it/s]\n",
      "Epoch 8 - Training: 100%|██████████| 64/64 [00:47<00:00,  1.36it/s, acc=0.997, loss=0.0604]\n",
      "Validating: 100%|██████████| 8/8 [00:05<00:00,  1.48it/s, acc=0.996, loss=0.0812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/16 - Train Loss: 0.0732, Train Acc: 0.9915, Val Loss: 0.0855, Val Acc: 0.9910\n",
      "Model saved to font_identifier_model_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Collecting val samples: 100%|██████████| 128/128 [00:07<00:00, 17.01it/s]\n",
      "Epoch 9 - Collecting train samples:  81%|████████▏ | 832/1024 [00:47<00:09, 21.01it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     val_samples \u001b[38;5;241m=\u001b[39m [future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(val_futures, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Collecting val samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     21\u001b[0m     train_futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(sample, sampler, font_cnt, sample_cnt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_samples_count)]\n\u001b[0;32m---> 22\u001b[0m     train_samples \u001b[38;5;241m=\u001b[39m [future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(train_futures, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Collecting train samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 将采样结果重新排布为 [epoch_length, batch_size] 的格式\u001b[39;00m\n\u001b[1;32m     25\u001b[0m train_batches \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m     val_samples \u001b[38;5;241m=\u001b[39m [future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(val_futures, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Collecting val samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     21\u001b[0m     train_futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(sample, sampler, font_cnt, sample_cnt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_samples_count)]\n\u001b[0;32m---> 22\u001b[0m     train_samples \u001b[38;5;241m=\u001b[39m [\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(train_futures, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Collecting train samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 将采样结果重新排布为 [epoch_length, batch_size] 的格式\u001b[39;00m\n\u001b[1;32m     25\u001b[0m train_batches \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Collecting train samples:  81%|████████▏ | 832/1024 [01:02<00:09, 21.01it/s]"
     ]
    }
   ],
   "source": [
    "def sample(sampler, font_cnt, sample_cnt, sample_source):\n",
    "    sample = sampler.sample(font_cnt=font_cnt, sample_cnt=sample_cnt, sample_source=sample_source)\n",
    "    return sample\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 收集一个 epoch 所需的所有训练样本\n",
    "    train_samples = []\n",
    "    val_samples = []\n",
    "\n",
    "    # 使用多线程采样所有数据\n",
    "    total_samples = epoch_length * batch_size\n",
    "    val_samples_count = total_samples // 8  # 1/8 的数据用于验证\n",
    "    train_samples_count = total_samples\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=32) as executor:\n",
    "        val_futures = [executor.submit(sample, sampler, font_cnt, sample_cnt, \"test\") for _ in range(val_samples_count)]\n",
    "        val_samples = [future.result() for future in tqdm(val_futures, desc=f\"Epoch {epoch + 1} - Collecting val samples\")]\n",
    "\n",
    "        train_futures = [executor.submit(sample, sampler, font_cnt, sample_cnt, \"train\") for _ in range(train_samples_count)]\n",
    "        train_samples = [future.result() for future in tqdm(train_futures, desc=f\"Epoch {epoch + 1} - Collecting train samples\")]\n",
    "\n",
    "    # 将采样结果重新排布为 [epoch_length, batch_size] 的格式\n",
    "    train_batches = []\n",
    "    for i in range(epoch_length):\n",
    "        batch_samples = train_samples[i * batch_size:(i + 1) * batch_size]\n",
    "        train_batches.append(batch_samples)\n",
    "\n",
    "    val_batches = []\n",
    "    val_length = len(val_samples) // batch_size\n",
    "    for i in range(val_length):\n",
    "        batch_samples = val_samples[i * batch_size:(i + 1) * batch_size]\n",
    "        val_batches.append(batch_samples)\n",
    "\n",
    "    # 创建训练集 Dataset 和 DataLoader\n",
    "    train_dataset = FontDataset(train_batches, transform=data_transforms)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # 创建验证集 Dataset 和 DataLoader\n",
    "    val_dataset = FontDataset(val_batches, transform=data_transforms)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    train_loss, train_acc = train_step(model, epoch, train_loader, optimizer, batch_size, font_cnt, sample_cnt)\n",
    "    val_loss, val_acc = validate(model, val_loader, batch_size, font_cnt, sample_cnt)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # 保存模型\n",
    "    model_save_path = f'font_identifier_model_epoch_{epoch + 1}.pth'\n",
    "    torch.save(model, model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
